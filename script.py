import json
from random import randint, choice
from datetime import datetime, timedelta

# Popular AI model names
popular_models = ["GPT-3", "BERT", "OpenAI Codex", "GPT-2", "AlphaGo"]

# General code part
general_code = '''
# Import necessary libraries
import gpt

# Load the model
model = gpt.load_model("your_model_path")

# Generate text
prompt = "Your prompt here"
output = model.generate_text(prompt)

print(output)
'''

# Function to generate fixture data for GPT instance
def create_gpt_fixture():
    # Generate random slug from popular model names
    slug = choice(popular_models)

    # Generate random date in the past for generated_date
    generated_date = datetime.now() - timedelta(days=randint(1, 365))

    # Description of the popular model with code to run it
    description = f'''
    {slug} is a popular AI model developed by its respective organization. It has been trained on a massive dataset and can perform various natural language processing tasks effectively. Below is an example code snippet to run {slug}:

    {general_code}
    '''

    # Select random owner ID between 1 and 10
    owner_id = randint(1, 10)

    # Select random tags between 1 and 10
    tag_ids = [randint(1, 10) for _ in range(randint(2, 3))]

    # Select random framework (PyTorch or TensorFlow)
    frameworks = choice(["PyTorch", "TensorFlow"])

    # Set total_view and total_upvote to 0
    total_view = 0
    total_upvote = 0

    # Select random activity summary ID between 1 and 5
    activity_summary_id = randint(1, 5)

    return {
        "model": "your_app.gpt",
        "pk": None,  # Will be autogenerated
        "fields": {
            "slug": slug,
            "generated_date": generated_date.strftime("%Y-%m-%d %H:%M:%S"),
            "description": description,
            "owner": owner_id,
            "tags": tag_ids,
            "frameworks": frameworks,
            "featured": False,
            "tryitout_link": "",
            "activity_summary": activity_summary_id,
            "total_view": total_view,
            "total_upvote": total_upvote
        }
    }

# Generate fixture data for 10 GPT instances
gpt_fixture_data = [create_gpt_fixture() for _ in range(10)]

# Dump fixture data to a file
with open("gpt_fixture.json", "w") as f:
    json.dump(gpt_fixture_data, f, indent=4)
